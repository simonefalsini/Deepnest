# THREAD SAFETY CRITICAL ANALYSIS - DeepNest C++ Core Components

**Data**: 2025-11-20
**Analisi**: DeepNestSolver, NestingEngine, NFPCache, ParallelProcessor, GeneticAlgorithm
**Focus**: Thread management e data references

---

## EXECUTIVE SUMMARY

Ho identificato **7 problemi critici** che causano crash (0xc0000005 access violation) nel codice NFP/nesting:

### üî¥ **PROBLEMA #1: USE-AFTER-FREE - PUNTATORI RAW AI POLYGON**
**Severit√†**: CRITICA
**Causa root**: `Individual::placement` contiene `std::vector<Polygon*>` che puntano a `NestingEngine::parts_`, ma i thread worker possono accedere a questi puntatori DOPO che `parts_` √® stato distrutto o ricreato.

### üî¥ **PROBLEMA #2: DANGLING REFERENCE - LAMBDA CAPTURE IN PARALLELPROCESSOR**
**Severit√†**: CRITICA
**Causa root**: `ParallelProcessor::processPopulation()` cattura `&population` e `&worker` per reference, ma questi oggetti possono essere distrutti mentre i thread sono ancora in esecuzione.

### üî¥ **PROBLEMA #3: PARTPOINTERS_ INVALIDATI DAL VECTOR RESIZE**
**Severit√†**: CRITICA
**Causa root**: `NestingEngine::partPointers_` contiene puntatori agli elementi di `parts_` vector. Se `parts_` viene modificato (resize, clear), tutti i puntatori diventano invalidi.

### üî¥ **PROBLEMA #4: NESSUN WAIT IN STOP() - THREAD ANCORA ATTIVI**
**Severit√†**: ALTA
**Causa root**: `NestingEngine::stop()` distrugge `parallelProcessor_` ma non attende che tutti i task nei thread siano completati prima di distruggere `placementWorker_` e `nfpCalculator_`.

### üî¥ **PROBLEMA #5: RECREATE PARALLELPROCESSOR SENZA SYNC**
**Severit√†**: ALTA
**Causa root**: `NestingEngine::start()` ricrea `parallelProcessor_` ma non garantisce che i vecchi thread siano completamente terminati.

### üü° **PROBLEMA #6: NFPCACHE ACCESSO CONCORRENTE AI POLYGON**
**Severit√†**: MEDIA
**Causa root**: NFPCache usa mutex per proteggere la map, ma i Polygon copiati dalla cache potrebbero contenere dati Boost.Polygon non thread-safe.

### üü° **PROBLEMA #7: PARTS_ MODIFICATO DURANTE PROCESSING**
**Severit√†**: MEDIA
**Causa root**: Nessun lock protegge `parts_` da modifiche concorrenti se `initialize()` viene chiamato mentre il processing √® attivo.

---

## DETAILED ANALYSIS

---

## PROBLEMA #1: USE-AFTER-FREE - PUNTATORI RAW AI POLYGON

### Descrizione Completa

**Individual.h, linea 33:**
```cpp
std::vector<Polygon*> placement;
```

Ogni Individual contiene un vettore di puntatori RAW ai Polygon. Questi puntatori puntano agli elementi del vector `NestingEngine::parts_`.

**Flusso del problema:**

1. **NestingEngine::initialize() - NestingEngine.cpp:140-144**
   ```cpp
   partPointers_.clear();
   for (auto& part : parts_) {
       partPointers_.push_back(&part);  // ‚Üê CREA PUNTATORI AGLI ELEMENTI DEL VECTOR
   }
   ```

2. **NestingEngine::initialize() - NestingEngine.cpp:148**
   ```cpp
   geneticAlgorithm_ = std::make_unique<GeneticAlgorithm>(partPointers_, config_);
   ```
   Passa `partPointers_` (che contengono puntatori a `parts_` elements) al GeneticAlgorithm.

3. **GeneticAlgorithm costruttore - GeneticAlgorithm.cpp:10**
   ```cpp
   parts_(adam)  // ‚Üê COPIA IL VECTOR DI PUNTATORI
   ```

4. **Population::initialize()** crea Individual con:
   ```cpp
   individual.placement = parts;  // ‚Üê OGNI INDIVIDUAL HA PUNTATORI AGLI ELEMENTI DI parts_
   ```

5. **ParallelProcessor::processPopulation() - ParallelProcessor.cpp:126**
   ```cpp
   Individual individualCopy = individual.clone();
   ```
   `clone()` copia il vector `placement`, che contiene i PUNTATORI RAW.

6. **Lambda worker thread - ParallelProcessor.cpp:144-148**
   ```cpp
   for (size_t j = 0; j < individualCopy.placement.size(); ++j) {
       Polygon part = *individualCopy.placement[j];  // ‚Üê DEREFERENZIA IL PUNTATORE
       part.rotation = individualCopy.rotation[j];
       parts.push_back(part);
   }
   ```

**SCENARIO DI CRASH:**

```
Thread Principal (UI):
1. Chiama NestingEngine::stop()
   ‚Üí parallelProcessor_.reset() (distrugge processor)
   ‚Üí parts_ rimane valido

2. Chiama NestingEngine::start() di nuovo (restart)
   ‚Üí parts_.clear()  // ‚Üê DISTRUGGE TUTTI I POLYGON NEL VECTOR!
   ‚Üí parts_.push_back(...)  // ‚Üê CREA NUOVI POLYGON IN NUOVE LOCAZIONI DI MEMORIA

Thread Worker (background):
3. Lambda ancora in esecuzione (non terminata durante stop)
   ‚Üí Polygon part = *individualCopy.placement[j];  // ‚Üê DEREFERENZIA PUNTATORE INVALIDO!
   ‚Üí üí• ACCESS VIOLATION 0xc0000005
```

**Perch√© succede:**
- `std::vector::clear()` distrugge tutti gli elementi
- I puntatori in `individualCopy.placement` puntano a memoria gi√† deallocata
- Quando il thread worker dereferenzia il puntatore, accede a memoria invalida

### Root Cause

**C++ Standard behavior:**
> When a vector is resized, moved, or cleared, all iterators, pointers, and references to its elements are invalidated.

`parts_` √® un `std::vector<Polygon>`. Quando viene fatto `clear()`:
1. Vengono chiamati i distruttori di tutti i Polygon
2. La memoria viene deallocata
3. Tutti i puntatori agli elementi diventano **dangling pointers**

### Impact

- ‚úÖ Spiega il crash 0xc0000005 in `addHole()` (accesso a memoria deallocata)
- ‚úÖ Spiega perch√© il crash avviene solo su restart (dopo stop+start)
- ‚úÖ Spiega perch√© il crash avviene con molti elementi (pi√π thread attivi)
- ‚úÖ Spiega perch√© PolygonExtractor non crasha (non fa mai restart)

### Soluzione Proposta

**Opzione A: Shared Pointers (CONSIGLIATA)**

Cambiare `std::vector<Polygon*>` ‚Üí `std::vector<std::shared_ptr<Polygon>>`

```cpp
// Individual.h
std::vector<std::shared_ptr<Polygon>> placement;

// NestingEngine.cpp
std::vector<std::shared_ptr<Polygon>> partPointers_;

for (auto& part : parts_) {
    partPointers_.push_back(std::make_shared<Polygon>(part));
}
```

**Vantaggi:**
- Reference counting automatico
- Polygon non vengono distrutti finch√© almeno un thread li sta usando
- Thread-safe (std::shared_ptr √® thread-safe per reference counting)

**Opzione B: Deep Copy dei Polygon (ALTERNATIVA)**

Copiare i Polygon invece di usare puntatori:

```cpp
// ParallelProcessor.cpp - linea 143
std::vector<Polygon> partsCopy;
for (size_t j = 0; j < individualCopy.placement.size(); ++j) {
    Polygon part = *individualCopy.placement[j];  // Copia gi√† fatta qui
    part.rotation = individualCopy.rotation[j];
    partsCopy.push_back(part);
}

// Ora partsCopy √® owned dal lambda e non dipende da individualCopy.placement
```

**Problema:** Questo non risolve il problema se `placement[j]` √® gi√† un dangling pointer.

**Opzione C: Lock durante clear (NON CONSIGLIATA)**

Aggiungere mutex e aspettare che tutti i thread finiscano prima di `clear()`.

**Problema:** Deadlock potential, performance impact.

---

## PROBLEMA #2: DANGLING REFERENCE - LAMBDA CAPTURE IN PARALLELPROCESSOR

### Descrizione Completa

**ParallelProcessor.cpp, linea 133:**
```cpp
enqueue([&population, index, sheetsCopy, &worker, individualCopy, this]() mutable {
    // ...
    PlacementWorker::PlacementResult result = worker.placeParts(sheetsCopy, parts);  // ‚Üê USA &worker

    {
        boost::lock_guard<boost::mutex> lock(this->mutex_);
        auto& individuals = population.getIndividuals();  // ‚Üê USA &population
        if (index < individuals.size()) {
            individuals[index].fitness = result.fitness;
            // ...
        }
    }
});
```

**Capture by reference:**
- `&population` - Reference alla Population
- `&worker` - Reference al PlacementWorker

**SCENARIO DI CRASH:**

```
Thread Principal:
1. NestingEngine::stop() viene chiamato
   ‚Üí parallelProcessor_->stop()
   ‚Üí threads_.join_all()  // ‚Üê Aspetta SOLO i thread, non i task
   ‚Üí parallelProcessor_.reset()  // ‚Üê Distrugge parallelProcessor

2. NestingEngine destructor continua
   ‚Üí placementWorker_.reset()  // ‚Üê DISTRUGGE IL WORKER! üíÄ
   ‚Üí geneticAlgorithm_.reset()  // ‚Üê DISTRUGGE POPULATION! üíÄ

Thread Worker (background):
3. Lambda task ancora nella coda (non eseguito)
4. Thread inizia a eseguire il task
   ‚Üí PlacementWorker::PlacementResult result = worker.placeParts(...)
   ‚Üí üí• DANGLING REFERENCE! worker √® gi√† distrutto!
   ‚Üí üí• ACCESS VIOLATION 0xc0000005
```

### Root Cause

**ParallelProcessor::stop() - ParallelProcessor.cpp:36-64**
```cpp
void ParallelProcessor::stop() {
    {
        boost::lock_guard<boost::mutex> lock(mutex_);
        if (stopped_) {
            return;
        }
        stopped_ = true;
        workGuard_.reset();
    }

    ioContext_.stop();
    threads_.join_all();  // ‚Üê ATTENDE SOLO I THREAD, NON I TASK NELLA CODA!
}
```

**Il problema:**
- `threads_.join_all()` aspetta che i thread terminino
- Ma i thread potrebbero ancora avere task nella coda `ioContext_`
- Quando `stop()` ritorna, `NestingEngine` distrugge `placementWorker_` e `geneticAlgorithm_`
- Ma i task nella coda hanno `&worker` e `&population` che ora sono dangling references!

### Impact

- ‚úÖ Spiega crash su stop durante nesting
- ‚úÖ Spiega crash su restart (stop + start rapido)
- ‚úÖ Spiega crash su exit durante nesting
- ‚úÖ Manifesto solo quando ci sono task ancora in coda

### Soluzione Proposta

**Opzione A: Flush della coda prima di stop (CONSIGLIATA)**

```cpp
void ParallelProcessor::stop() {
    {
        boost::lock_guard<boost::mutex> lock(mutex_);
        if (stopped_) {
            return;
        }
        stopped_ = true;
        workGuard_.reset();
    }

    // CRITICAL FIX: Wait for ALL pending tasks to complete
    while (!ioContext_.stopped()) {
        std::this_thread::sleep_for(std::chrono::milliseconds(10));

        // Poll to check if there are pending tasks
        if (ioContext_.poll() == 0) {
            break;  // No more tasks
        }
    }

    ioContext_.stop();
    threads_.join_all();
}
```

**Opzione B: Capture by value (PARZIALE)**

Catturare copie invece di reference:

```cpp
// NON FUNZIONA: population √® grande e non copyable
// worker √® non-copyable (contiene mutex)
```

**Opzione C: Shared ownership (CONSIGLIATA INSIEME AD OPZIONE A)**

Usare `std::shared_ptr` per `placementWorker_` e passarlo alla lambda:

```cpp
// NestingEngine.h
std::shared_ptr<PlacementWorker> placementWorker_;

// ParallelProcessor.cpp
auto workerPtr = placementWorker_;  // Incrementa ref count
enqueue([&population, index, sheetsCopy, workerPtr, individualCopy, this]() mutable {
    PlacementWorker::PlacementResult result = workerPtr->placeParts(sheetsCopy, parts);
    // ...
});
```

---

## PROBLEMA #3: PARTPOINTERS_ INVALIDATI DAL VECTOR RESIZE

### Descrizione

**NestingEngine.h, linea 343:**
```cpp
std::vector<Polygon*> partPointers_;
```

**NestingEngine.h, linea 340:**
```cpp
std::vector<Polygon> parts_;
```

**NestingEngine.cpp, linee 140-144:**
```cpp
partPointers_.clear();
for (auto& part : parts_) {
    partPointers_.push_back(&part);  // ‚Üê PUNTATORI AGLI ELEMENTI DI parts_
}
```

### Root Cause

**C++ vector invalidation rules:**

Quando un `std::vector` viene modificato (resize, push_back, erase, clear), **tutti i puntatori, reference e iteratori agli elementi possono essere invalidati**.

**Scenario di invalidazione:**

```cpp
std::vector<Polygon> parts_;  // Capacit√† iniziale: 10

parts_.push_back(polygon1);  // Size: 1
parts_.push_back(polygon2);  // Size: 2
// ...
parts_.push_back(polygon11); // Size: 11 ‚Üí RESIZE! üíÄ

// ‚Üê Tutti i puntatori creati prima del resize sono ora INVALIDI!
```

**Nel nostro codice:**

1. `initialize()` crea `parts_` con size N
2. Crea `partPointers_` con puntatori agli elementi
3. **Se mai `parts_` viene modificato** (anche solo un `parts_.push_back()`), tutti i puntatori diventano invalidi

### Current Code Safety

**Attualmente SICURO perch√©:**
- `parts_` viene popolato in `initialize()`
- Dopo, `parts_` non viene MAI modificato fino a `clear()`
- `clear()` viene chiamato solo in `initialize()` che ricrea `partPointers_`

**Tuttavia √® FRAGILE:**
- Se qualcuno aggiunge codice che modifica `parts_` (es. `parts_.resize()`, `parts_.push_back()`), instant crash
- Non c'√® protezione o invariant checking

### Soluzione Proposta

Usare `shared_ptr` (vedi Problema #1, Opzione A) per eliminare la dipendenza dalla stabilit√† del vector.

---

## PROBLEMA #4: NESSUN WAIT IN STOP() - THREAD ANCORA ATTIVI

### Descrizione

**NestingEngine::stop() - NestingEngine.cpp:176-184:**
```cpp
void NestingEngine::stop() {
    running_ = false;
    if (parallelProcessor_) {
        parallelProcessor_->stop();
        parallelProcessor_.reset();  // ‚Üê DISTRUGGE PROCESSOR IMMEDIATAMENTE
    }
}
```

**NestingEngine destructor - NestingEngine.cpp:26-52:**
```cpp
NestingEngine::~NestingEngine() {
    stop();

    nfpCache_.clear();

    if (parallelProcessor_) {
        parallelProcessor_.reset();  // ‚Üê Gi√† nullptr da stop()
    }

    if (placementWorker_) {
        placementWorker_.reset();  // ‚Üê DISTRUGGE WORKER MENTRE THREAD ATTIVI!
    }

    if (nfpCalculator_) {
        nfpCalculator_.reset();
    }
}
```

### Root Cause

**Ordine di distruzione errato:**

1. `parallelProcessor_->stop()` ferma i thread e chiama `join_all()`
2. `parallelProcessor_.reset()` distrugge il processor
3. `placementWorker_.reset()` **distrugge il worker**
4. **MA:** Le lambda potrebbero ancora avere `&worker` che ora √® dangling!

**Il problema √® che `ParallelProcessor::stop()` non flush i task pendenti prima di ritornare.**

### Impact

- Crash quando si chiama `stop()` mentre ci sono task attivi
- Crash quando si esce dall'applicazione durante nesting

### Soluzione Proposta

**Fix #1: Flush task queue in ParallelProcessor::stop()**

Vedi Problema #2, Opzione A.

**Fix #2: Aggiungere wait in NestingEngine::stop()**

```cpp
void NestingEngine::stop() {
    running_ = false;
    if (parallelProcessor_) {
        parallelProcessor_->stop();  // ‚Üê Questo ora aspetta il flush
        parallelProcessor_->waitAll();  // ‚Üê Wait esplicito per tutti i task
        parallelProcessor_.reset();
    }
}
```

---

## PROBLEMA #5: RECREATE PARALLELPROCESSOR SENZA SYNC

### Descrizione

**NestingEngine::start() - NestingEngine.cpp:160-165:**
```cpp
// CRITICAL FIX: Recreate ParallelProcessor if it was previously stopped
if (!parallelProcessor_) {
    parallelProcessor_ = std::make_unique<ParallelProcessor>(config_.threads);
}
```

**NestingEngine::stop() - NestingEngine.cpp:176-184:**
```cpp
void NestingEngine::stop() {
    running_ = false;
    if (parallelProcessor_) {
        parallelProcessor_->stop();
        parallelProcessor_.reset();  // ‚Üê Distrugge processor
    }
}
```

### Scenario

```
User: Start nesting
  ‚Üí parallelProcessor_ creato
  ‚Üí Thread pool attivo

User: Stop nesting
  ‚Üí parallelProcessor_->stop()
  ‚Üí threads_.join_all()  // ‚Üê Aspetta thread
  ‚Üí parallelProcessor_.reset()  // ‚Üê Distrugge processor

User: Start nesting AGAIN
  ‚Üí parallelProcessor_ = std::make_unique<ParallelProcessor>(...)  // ‚Üê CREA NUOVO
  ‚Üí Nuovo thread pool
```

### Root Cause

**Gap di sincronizzazione:**

Tra il momento in cui `threads_.join_all()` ritorna e il momento in cui viene creato il nuovo `ParallelProcessor`, potrebbero esserci ancora:
- Task nella vecchia coda `ioContext_`
- Callback pendenti
- Mutex locks non rilasciati

**Se il nuovo `ParallelProcessor` viene creato immediatamente, potrebbe:**
- Riciclare gli stessi thread ID
- Avere race condition con cleanup non completo del vecchio processor

### Impact

- Crash intermittenti su restart (timing-dependent)
- Deadlock potenziali
- Corruzione di stato

### Soluzione Proposta

**Fix: Aggiungere delay o barrier**

```cpp
void NestingEngine::stop() {
    running_ = false;
    if (parallelProcessor_) {
        parallelProcessor_->stop();
        parallelProcessor_->waitAll();  // ‚Üê WAIT FOR QUEUE FLUSH
        parallelProcessor_.reset();

        // CRITICAL: Small delay to ensure complete cleanup
        std::this_thread::sleep_for(std::chrono::milliseconds(50));
    }
}
```

---

## PROBLEMA #6: NFPCACHE ACCESSO CONCORRENTE AI POLYGON

### Descrizione

**NFPCache.h, linee 58-60:**
```cpp
mutable boost::shared_mutex mutex_;
std::unordered_map<std::string, std::vector<Polygon>> cache_;
```

**NFPCache.cpp, linee 64-68:**
```cpp
if (it != cache_.end()) {
    result = it->second;  // ‚Üê COPIA IL VECTOR<POLYGON>
    ++hits_;
    return true;
}
```

### Root Cause

**Thread safety attuale:**
- ‚úÖ La `boost::shared_mutex` protegge la `std::unordered_map`
- ‚úÖ Multiple thread possono leggere contemporaneamente (shared_lock)
- ‚úÖ Solo un thread pu√≤ scrivere (unique_lock)

**Problema:**
- `result = it->second` copia il `std::vector<Polygon>`
- Ogni `Polygon` contiene `std::vector<Point>`, `children`, ecc.
- Se `Polygon` internamente usa dati Boost.Polygon (tipo `polygon_set_data`), questi potrebbero non essere thread-safe durante la copia

**MinkowskiSum.cpp** aggiunge NFP alla cache con `insert()`:

```cpp
nfpCache_.insert(keyA, keyB, nfpResult, inner);
```

Se due thread:
- Thread 1: Legge dalla cache (copia Polygon)
- Thread 2: Inserisce nella cache (modifica Polygon internals)

Potrebbe esserci race condition **dentro** Boost.Polygon data structures.

### Impact

- ‚ö†Ô∏è Potenziale crash in Boost.Polygon durante copia
- ‚ö†Ô∏è Corruzione di dati geometrici
- ‚ö†Ô∏è Difficile da riprodurre (race condition)

### Soluzione Proposta

**Opzione A: Deep Copy Defensiva**

Assicurarsi che la copia di Polygon sia veramente deep e thread-safe:

```cpp
bool NFPCache::find(const NFPKey& key, std::vector<Polygon>& result) const {
    boost::shared_lock<boost::shared_mutex> lock(mutex_);

    std::string keyStr = generateKey(key);
    auto it = cache_.find(keyStr);

    if (it != cache_.end()) {
        // Deep copy each polygon to ensure thread safety
        result.clear();
        result.reserve(it->second.size());
        for (const auto& polygon : it->second) {
            result.push_back(polygon.deepCopy());  // ‚Üê Serve implementazione deepCopy()
        }
        ++hits_;
        return true;
    }

    ++misses_;
    return false;
}
```

**Opzione B: Polygon Immutabile**

Fare in modo che Polygon sia immutable dopo la creazione, garantendo thread-safety.

**Opzione C: Serialize/Deserialize**

Invece di copiare direttamente, serializzare e deserializzare Polygon per garantire deep copy:

```cpp
Polygon polygon = it->second[0];
std::string serialized = polygon.serialize();
Polygon copy = Polygon::deserialize(serialized);
```

---

## PROBLEMA #7: PARTS_ MODIFICATO DURANTE PROCESSING

### Descrizione

**NestingEngine::initialize() - NestingEngine.cpp:68:**
```cpp
parts_.clear();  // ‚Üê CANCELLA TUTTI I POLYGON
```

**NestingEngine::step() - NestingEngine.cpp:257-262:**
```cpp
parallelProcessor_->processPopulation(
    geneticAlgorithm_->getPopulationObject(),
    sheets_,
    *placementWorker_,
    config_.threads
);
```

### Root Cause

**Nessun lock protegge `parts_` da:**
- Modifiche concorrenti
- Clear durante processing

**Scenario teorico di crash:**

```
User: Chiama initialize() mentre nesting √® ancora running

Thread UI:
  ‚Üí NestingEngine::initialize()
  ‚Üí parts_.clear()  // ‚Üê DISTRUGGE TUTTI I POLYGON

Thread Worker (background):
  ‚Üí Lambda esegue
  ‚Üí Polygon part = *individualCopy.placement[j];  // ‚Üê DANGLING POINTER!
  ‚Üí üí• CRASH
```

**Attualmente protetto da:**
- `initialize()` viene chiamato solo da `DeepNestSolver::start()`
- `start()` fallisce se `running_ == true`

```cpp
if (running_) {
    throw std::runtime_error("Nesting is already running");
}
```

**Tuttavia:**
- Non c'√® invariant checking nel codice
- Se qualcuno chiama direttamente `NestingEngine::initialize()` mentre running, crash

### Soluzione Proposta

**Fix: Aggiungere check in initialize()**

```cpp
void NestingEngine::initialize(...) {
    if (running_) {
        throw std::runtime_error("Cannot initialize while nesting is running. Call stop() first.");
    }

    // ... resto del codice
}
```

---

## SUMMARY MATRIX

| Problema | Severit√† | Causa Root | Componenti Coinvolti | Impact Crash |
|----------|----------|------------|---------------------|--------------|
| #1 USE-AFTER-FREE Puntatori | üî¥ CRITICA | Raw pointers a vector elements | Individual, NestingEngine, ParallelProcessor | ‚úÖ Stop+Restart |
| #2 Dangling Reference Lambda | üî¥ CRITICA | Lambda capture &population, &worker | ParallelProcessor, NestingEngine | ‚úÖ Stop durante nesting |
| #3 partPointers_ Invalidation | üî¥ CRITICA | Puntatori invalidati da vector resize | NestingEngine | ‚ö†Ô∏è Potenziale |
| #4 No Wait in Stop | üî¥ ALTA | Task queue non flushed | ParallelProcessor, NestingEngine | ‚úÖ Stop+Exit |
| #5 Recreate Processor | üî¥ ALTA | Gap di sincronizzazione | NestingEngine, ParallelProcessor | ‚ö†Ô∏è Intermittente |
| #6 NFPCache Polygon Copy | üü° MEDIA | Boost.Polygon non thread-safe copy | NFPCache, MinkowskiSum | ‚ö†Ô∏è Race condition |
| #7 parts_ Modifica Concorrente | üü° MEDIA | Nessun lock su parts_ | NestingEngine | ‚ö†Ô∏è Protetto da logic |

---

## PRIORITY FIXES

### P0 - CRITICAL (Must Fix)

1. **Fix Problema #1**: Usare `std::shared_ptr<Polygon>` invece di raw pointers
2. **Fix Problema #2**: Flush task queue in `ParallelProcessor::stop()`
3. **Fix Problema #4**: Aggiungere wait esplicito in `NestingEngine::stop()`

### P1 - HIGH (Should Fix)

4. **Fix Problema #5**: Aggiungere delay dopo `parallelProcessor_.reset()`
5. **Fix Problema #3**: Shared pointers (risolto insieme a #1)

### P2 - MEDIUM (Nice to Have)

6. **Fix Problema #6**: Implementare deep copy thread-safe per Polygon
7. **Fix Problema #7**: Aggiungere check in `initialize()`

---

## RECOMMENDED IMPLEMENTATION ORDER

### FASE 1: Thread Lifecycle Management (Risolve crash su Stop/Restart)

**File: ParallelProcessor.cpp**

```cpp
void ParallelProcessor::stop() {
    {
        boost::lock_guard<boost::mutex> lock(mutex_);
        if (stopped_) {
            return;
        }
        stopped_ = true;
        workGuard_.reset();
    }

    // CRITICAL FIX: Flush all pending tasks
    LOG_THREAD("Flushing pending tasks before stopping threads");
    while (!ioContext_.stopped()) {
        std::this_thread::sleep_for(std::chrono::milliseconds(10));
        size_t remaining = ioContext_.poll();
        if (remaining == 0) {
            LOG_THREAD("All tasks flushed");
            break;
        }
        LOG_THREAD("Still have " << remaining << " tasks pending");
    }

    ioContext_.stop();
    LOG_THREAD("Waiting for all threads to join");
    threads_.join_all();
    LOG_THREAD("All threads joined successfully");
}
```

**File: NestingEngine.cpp**

```cpp
void NestingEngine::stop() {
    if (!running_) {
        return;
    }

    LOG_NESTING("Stopping nesting engine");
    running_ = false;

    if (parallelProcessor_) {
        LOG_THREAD("Stopping parallel processor");
        parallelProcessor_->stop();  // ‚Üê Questo ora flush i task
        parallelProcessor_->waitAll();  // ‚Üê Wait esplicito
        parallelProcessor_.reset();

        // Small delay to ensure complete cleanup
        std::this_thread::sleep_for(std::chrono::milliseconds(50));
        LOG_THREAD("Parallel processor stopped and destroyed");
    }

    LOG_NESTING("Nesting engine stopped");
}
```

### FASE 2: Shared Ownership (Risolve Use-After-Free)

**File: Individual.h**

```cpp
// Cambia da:
std::vector<Polygon*> placement;

// A:
std::vector<std::shared_ptr<Polygon>> placement;
```

**File: NestingEngine.h**

```cpp
// Cambia da:
std::vector<Polygon*> partPointers_;

// A:
std::vector<std::shared_ptr<Polygon>> partPointers_;
```

**File: NestingEngine.cpp**

```cpp
void NestingEngine::initialize(...) {
    // ...

    // Create shared pointers for GA
    partPointers_.clear();
    for (auto& part : parts_) {
        partPointers_.push_back(std::make_shared<Polygon>(part));
    }

    geneticAlgorithm_ = std::make_unique<GeneticAlgorithm>(partPointers_, config_);
}
```

**File: ParallelProcessor.cpp**

```cpp
// Lambda - linea 144-148 cambia da:
for (size_t j = 0; j < individualCopy.placement.size(); ++j) {
    Polygon part = *individualCopy.placement[j];  // ‚Üê Raw pointer dereference
    part.rotation = individualCopy.rotation[j];
    parts.push_back(part);
}

// A:
for (size_t j = 0; j < individualCopy.placement.size(); ++j) {
    Polygon part = *individualCopy.placement[j];  // ‚Üê Shared pointer dereference (same syntax!)
    part.rotation = individualCopy.rotation[j];
    parts.push_back(part);
}
```

**Nota**: La sintassi rimane identica perch√© `std::shared_ptr` overload `operator*`.

### FASE 3: Shared PlacementWorker (Risolve Dangling Reference)

**File: NestingEngine.h**

```cpp
// Cambia da:
std::unique_ptr<PlacementWorker> placementWorker_;

// A:
std::shared_ptr<PlacementWorker> placementWorker_;
```

**File: NestingEngine.cpp - costruttore**

```cpp
placementWorker_ = std::make_shared<PlacementWorker>(config_, *nfpCalculator_);
```

**File: ParallelProcessor.cpp**

```cpp
void ParallelProcessor::processPopulation(
    Population& population,
    const std::vector<Polygon>& sheets,
    PlacementWorker& worker,  // ‚Üê Ancora reference
    int maxConcurrent
) {
    // ...

    for (size_t i = 0; i < individuals.size(); ++i) {
        // ...

        // CRITICAL: Capture shared_ptr to worker to ensure it stays alive
        std::shared_ptr<PlacementWorker> workerPtr = ???;  // ‚Üê PROBLEMA: worker √® reference!

        enqueue([&population, index, sheetsCopy, workerPtr, individualCopy, this]() mutable {
            PlacementWorker::PlacementResult result = workerPtr->placeParts(sheetsCopy, parts);
            // ...
        });
    }
}
```

**PROBLEMA:** `processPopulation` riceve `PlacementWorker&`, non `shared_ptr`.

**SOLUZIONE:** Cambiare signature:

```cpp
// ParallelProcessor.h
void processPopulation(
    Population& population,
    const std::vector<Polygon>& sheets,
    std::shared_ptr<PlacementWorker> worker,  // ‚Üê Cambia a shared_ptr
    int maxConcurrent = 0
);

// ParallelProcessor.cpp
void ParallelProcessor::processPopulation(
    Population& population,
    const std::vector<Polygon>& sheets,
    std::shared_ptr<PlacementWorker> worker,
    int maxConcurrent
) {
    // ...

    enqueue([&population, index, sheetsCopy, worker, individualCopy, this]() mutable {
        PlacementWorker::PlacementResult result = worker->placeParts(sheetsCopy, parts);
        // ...
    });
}

// NestingEngine.cpp - chiamata cambia da:
parallelProcessor_->processPopulation(
    geneticAlgorithm_->getPopulationObject(),
    sheets_,
    *placementWorker_,  // ‚Üê Dereference
    config_.threads
);

// A:
parallelProcessor_->processPopulation(
    geneticAlgorithm_->getPopulationObject(),
    sheets_,
    placementWorker_,  // ‚Üê Passa shared_ptr direttamente
    config_.threads
);
```

---

## TESTING STRATEGY

### Test 1: Stop durante nesting
```
1. Load 154 parts
2. Start nesting
3. Dopo 5 generazioni, Stop
4. Verificare: No crash, clean shutdown
5. Check logs: "All tasks flushed", "All threads joined"
```

### Test 2: Restart rapido
```
1. Load 154 parts
2. Start nesting
3. Dopo 3 generazioni, Stop
4. Wait 100ms
5. Start nesting again
6. Verificare: No crash, restart pulito
```

### Test 3: Exit durante nesting
```
1. Load 154 parts
2. Start nesting
3. Dopo 5 generazioni, chiudi applicazione
4. Verificare: No crash, exit pulito
5. Check logs: Destructor completo
```

### Test 4: Stress test - Multiple cycles
```
for (int i = 0; i < 10; i++) {
    Start nesting
    Wait 2 generazioni
    Stop
    Wait 50ms
}
Verificare: No crash, no memory leak
```

---

## EXPECTED RESULTS

Dopo l'implementazione di tutti i fix:

‚úÖ No crash su Stop durante nesting
‚úÖ No crash su Restart (Stop + Start)
‚úÖ No crash su Exit durante nesting
‚úÖ No memory leaks
‚úÖ Thread-safe operations
‚úÖ Stable su multiple cycles

---

## CONCLUSIONI

I crash 0xc0000005 sono causati da una combinazione di:

1. **Raw pointers a vector elements** che diventano invalidi quando il vector viene modificato
2. **Lambda capture by reference** che catturano oggetti che vengono distrutti prima che il task venga eseguito
3. **Task queue non flushed** prima della distruzione degli oggetti

La soluzione richiede:
- **Shared ownership** per Polygon e PlacementWorker
- **Task queue flush** in ParallelProcessor::stop()
- **Wait esplicito** in NestingEngine::stop()

Questi fix risolvono tutti e 3 gli scenari di crash riportati dall'utente.

---

**FINE ANALISI**
